[project]
name = "fluid-server"
version = "0.1.0"
description = "Portable OpenAI server for your Windows Desktop apps"
readme = "README.md"
requires-python = "==3.10.*"
license = { text = "Apache 2.0" }
authors = [{ name = "Fluid Inference" }]

dependencies = [
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.30.0",
    "pydantic>=2.0",
    "python-multipart>=0.0.6",
    "openvino>=2025.2.0",
    "openvino-genai>=2025.2.0",
    "huggingface-hub>=0.20.0",
    "numpy>=1.24.0",
    "librosa>=0.10.0",
    "pyinstaller>=6.15.0",
    "soundfile>=0.13.1",
]

[tool.uv]
dev-dependencies = [
    "openai>=1.100.1",
    "pyinstaller>=6.0.0",
    "ty>=0.0.1a18",
    "ruff>=0.8.0",
]

[tool.ruff]
target-version = "py310"
line-length = 100
indent-width = 4

[tool.ruff.lint]
select = [
    "E",    # pycodestyle errors
    "W",    # pycodestyle warnings
    "F",    # pyflakes
    "I",    # isort
    "B",    # flake8-bugbear
    "C4",   # flake8-comprehensions
    "UP",   # pyupgrade
]
ignore = [
    "E501",  # line too long (handled by formatter)
    "B008",  # do not perform function calls in argument defaults
    "W191",  # indentation contains tabs
]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"
skip-magic-trailing-comma = false
line-ending = "auto"

[tool.ruff.lint.isort]
known-first-party = ["fluid_server"]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src"]

# Entry point for the module
[project.scripts]
fluid-server = "fluid_server.__main__:main"
